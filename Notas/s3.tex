\documentclass[apuntes]{subfiles}

\begin{document}

\section{Dependencia e independencia lineal, bases y dimensión} \label{Sec: Dependencia e independencia lineal, bases y dimensión}

\subsection*{Dependencia e independencia lineal} \label{Ssec: Dependencia e independencia lineal}

Como se vio en la sección anterior, un vector puede ser expresado como diferentes combinaciones lineales de otros vectores del mismo espacio. En particular, el vector nulo $\mathbf{0}$ de cualquier espacio vectorial $V$ puede ser obtenido a través de la \emph{combinación lineal trivial} de cualesquiera $n$ vectores del espacio: sólo basta con que todos los coeficientes sean cero, i.e. $$0\mathbf{v}_1+0\mathbf{v}_2+...+0\mathbf{v}_n=\mathbf{0}, \hspace{3mm}\forall\hspace{1.5mm}\mathbf{v}_1 \mathbf{v}_2, ...,\mathbf{v}_n \in V.$$ Sin embargo, también pueden existir combinaciones lineales entre $n$ vectores de un espacio vectorial $V$ que den como resultado $\mathbf{0}$ pero sean no triviales (es decir, tengan coeficientes distintos de cero), e.g., en $\mathbb{R}^2, 7\begin{pmatrix} 1 & 1 \end{pmatrix}+5\begin{pmatrix} -1 & 1 \end{pmatrix}+2\begin{pmatrix} -1 & -6 \end{pmatrix}=\begin{pmatrix} 0 & 0 \end{pmatrix}$. Una consecuencia de este hecho es que podamos despejar a cualquiera de los vectores y expresarlo como combinación lineal de los demás; por ejemplo, $\begin{pmatrix} 1 & 1 \end{pmatrix}=-\frac{5}{7}\begin{pmatrix} -1 & 1 \end{pmatrix}-\frac{2}{7}\begin{pmatrix} -1 & -6 \end{pmatrix}$, ó $\begin{pmatrix} -1 & -6 \end{pmatrix} = -\frac{7}{2}\begin{pmatrix} 1 & 1 \end{pmatrix}-\frac{5}{2}\begin{pmatrix} -1 & 1 \end{pmatrix},$ etc. Este importante hecho motiva la siguiente definición.

\subsubsection*{Definición de dependencia e independencia lineal} \label{Def:Dependencia_e_independencia_lineal}

\begin{tcolorbox}

    \underline{Def.} Sea $V$ un espacio vectorial y $\mathbf{v}_1,\mathbf{v}_2,...,\mathbf{v}_n\in V$. Decimos que los vectores $\mathbf{v}_1,\mathbf{v}_2, ...,\mathbf{v}_n$ son \emph{linealmente independientes} entre sí si la única combinación lineal de ellos que da como resultado el vector nulo es la trivial (i.e., en la cual todos los coeficientes son cero). Matemáticamente, $$\mathbf{v}_1,\mathbf{v}_2, ..., \mathbf{v}_n \hspace{1.5mm} \text{son} \hspace{1.5mm} l.i. \iff (c_1\mathbf{v}_1+c_2\mathbf{v}_2+...+c_n\mathbf{v}_n=\mathbf{0}\implies c_1,c_2, ...,c_n=0).$$

    En cambio, decimos que $\mathbf{v}_1,\mathbf{v}_2, ..., \mathbf{v}_n$ son \emph{linealmente dependientes} si existe al menos una combinación lineal no trivial que dé como resultado el vector nulo o, equivalentemente, si cualquiera de los vectores $\mathbf{v}_i$ puede ser expresado como una combinación lineal de los demás. \\

    Si todos los vectores de un conjunto $S$ son linealmente dependientes (independientes) entre sí, se dice que el conjunto $S$ es linealmente dependiente (independiente)\footnote{Observemos que cualquier conjunto que contenga al vector nulo será linealmente dependiente.}.
\end{tcolorbox}

Por ejemplo, en $\mathbb{R}^2$ los vectores $\mathbf{u}_1=\begin{pmatrix} 1 & 5 \end{pmatrix}$ y $\mathbf{u}_2=\begin{pmatrix} -3 & -15 \end{pmatrix}$ son linealmente dependientes, ya que $\mathbf{u}_2=-3\mathbf{u}_1$, por lo cual $3\mathbf{u}_1+\mathbf{u}_2=\mathbf{0}$; por otro lado, los vectores $\mathbf{v}_1=\begin{pmatrix} 1 & 2 \end{pmatrix}$ y $\mathbf{v}_2=\begin{pmatrix} 1 & 3 \end{pmatrix}$ son linealmente independientes, ya que no existe un número $c\in\mathbb{R}$ tal que $\mathbf{v}_1=c\mathbf{v}_2.$. Notemos que, como nuestros vectores en este caso son $2-$tuplas, las ecuaciones $\mathbf{u}_2=-3\mathbf{u}_1$ y $\mathbf{v}_1=c\mathbf{v}_2$ son en realidad la notación compactada para un \emph{sistema de ecuaciones}, con una ecuación por cada entrada del vector. En particular, la ecuación $\mathbf{v}_1=c\mathbf{v}_2$ puede ser reescrita como $$\begin{pmatrix} 1 & 2 \end{pmatrix}=c\begin{pmatrix} 1 & 3 \end{pmatrix}\iff 1=c1 \hspace{1.5mm} \land\hspace{1.5mm} 2=c3,$$ de donde vemos directamente que no existe solución para $c$, por lo cual estos vectores son linealmente independientes. \\

    En general, cuando expresamos combinaciones lineales del tipo $\mathbf{v}=c_1\mathbf{u}_1+...+c_n\mathbf{u}_n$ en donde los vectores son dados pero los coeficientes son desconocidos, éstos útlimos se vuelven las \emph{incógnitas} del \emph{sistema de ecuaciones algebráicas} dado por la ecuación $\mathbf{v}=c_1\mathbf{u}_1+...+c_n\mathbf{u}_2$. El número de ecuaciones del sistema dependerá de la naturaleza de los vectores, mientras que el número de incógnitas será igual al número de coeficientes desconocidos. Por lo tanto, la pregunta de si un vector es linealmente independiente o dependiente de otro(s) se reduce a la de si el sistema de ecuaciones asociado a la combinación lineal de ellos que da como resultado el vector nulo tiene una solución no trivial o no. \\

Para ver más ejemplos de conjuntos de vectores linealmente dependientes e independientes pueden consultar, e.g., el Friedberg (págs. 36-38), el Lang introductorio (págs. 104-109), etc. 

\subsubsection*{Interpretación geométrica de la dependencia e independencia lineal}

Como ya mencionamos, si un vector $\mathbf{v}_n\in V$ es linealmente \emph{dependiente} de otros vectores $\mathbf{v}_1, \mathbf{v}_2, ..., \textbf{v}_m\in V$, entonces puede ser expresado como combinación lineal de esos vectores. Geométricamente, en los espacios vectoriales reales $\mathbb{R}^2$ y $\mathbb{R}^3$ esto quiere decir que es posible reescalar y combinar (mediante la Ley del paralelogramo) las flechas de los vectores $\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_m$ y obtener, como resultado final, a $\mathbf{v}_n$. Adicionalmente, en el espacio vectorial complejo $\mathbb{C}$, también se podrían estar rotando los vectores $\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_m$ \textemdash además de reescalarlos y combinarlos\textemdash \hspace{0.5mm} para formar, finalmente, a $\mathbf{v}_n$. Si son linealmente \emph{independientes}, entonces lo anterior no es posible.

\begin{ejer}
    Sea $n_i$ el $i$-ésimo dígito de tu número de cuenta. Determina si los vectores complejos $\begin{pmatrix} n_1 + i(n_2) \end{pmatrix}$ y $\begin{pmatrix} n_3 + i(n_4) \end{pmatrix}$ son linealmente dependientes o independientes en $(\mathbb{C},\mathbb{C})$ y muéstralo gráficamente en el plano complejo. Luego, repite el mismo ejercicio para los vectores reales $\begin{pmatrix} n_1 & n_4 & n_7 \end{pmatrix}, \begin{pmatrix} n_2 & n_5 & n_8 \end{pmatrix}$ y $\begin{pmatrix} n_3 & n_6 & n_9 \end{pmatrix}\in\mathbb{R}^3.$ ¿Cuáles son los conjuntos linealmente independientes más grandes que puedes formar usando a estos vectores? 
\end{ejer}

\subsubsection*{Algunos teoremas sobre dependencia e independencia lineal} \label{Teo:Dependencia_e_independencia_lineal} 

\begin{teo}\label{teo:Unicidad de combinación lineal en independencia lineal}

    Sea $V$ un espacio vectorial y $\mathbf{v_1}, \mathbf{v_2}, ..., \mathbf{v}_n$ vectores linealmente independientes de $V$. Sean $c_1, c_2, ..., c_n\in K$ y $d_1, d_2, ..., d_n\in K$ tales que $$c_1\mathbf{v}_1+c_2\mathbf{v}_2+...+c_n\mathbf{v}_n=d_1\mathbf{v}_1+d_2\mathbf{v}_2+...+d_n\mathbf{v}_n,$$ entonces se tiene que $c_i=d_i\hspace{3mm}\forall\hspace{1.5mm}i\in\{1,2, ..., n\}$.

    \begin{proof}

        $$c_1\mathbf{v_1}+c_2\mathbf{v}_2+...+c_n\mathbf{v}_n=d_1\mathbf{v}_1+d_2\mathbf{v}_2+...+d_n\mathbf{v}_n\iff(c_1-d_1)\mathbf{v}_1+(c_2-d_2)\mathbf{v}_2+...+(c_n-d_n)\mathbf{v}_n=\mathbf{0}.$$ Pero, ya que por hipótesis estos vectores son linealmente independientes, entonces por definición $$c_i-d_i=0\hspace{3mm}\forall\hspace{1.5mm}i\in\{1,2, ...,n\}\iff c_i=d_i\hspace{3mm}\forall\hspace{1.5mm}i\in\{1,2, ...,n\}.$$

    \end{proof}

    Este teorema nos dice que si un vector es resultado de una combinación lineal de vectores linealmente independientes, entonces esa combinación lineal es \emph{la única} que da como resultado a ese vector. Es decir, que si $\mathbf{u}=c_1\mathbf{v}_1+c_2\mathbf{v}_2+...+c_n\mathbf{v}_n$ y $\{\mathbf{v}_1,\mathbf{v}_2, ...,\mathbf{v}_n\}\hspace{1.5mm}\text{es}\hspace{1.5mm} l.i.$ entonces no existe otra combinación de escalaras y vectores $c_i \mathbf{v}_i$ tal que la suma de todos ellos dé $\mathbf{u}$.

\end{teo}

\begin{teo}\label{teo: Remover vectores a un conjunto linealmente independiente da un conjunto linealmente independiente}

    Sean $V$ un espacio vectorial y $S_1,S_2$ subconjuntos de $V$ tales que $S_1\subseteq S_2\subseteq V$. Si $S_2$ es linealmente independiente, entonces $S_1$ también es linealmente independiente.

\begin{proof}

    Sean $S_1=\{\mathbf{v}_1,\mathbf{v}_2, ..., \mathbf{v}_k\}$ y $S_2=\{\mathbf{v}_1,\mathbf{v}_2, ..., \mathbf{v}_n\}$ con $k\leq n$. Ya que por hipótesis $S_2$ es $l.i.$, por definición se cumple que $$c_1\mathbf{v}_1+c_2\mathbf{v}_2+...+c_n\mathbf{v}_n=\mathbf{0}\iff c_i=0\hspace{3mm}\forall\hspace{1.5mm}  i\in\{1,2, ..., n\}.$$ Si $k=n$ entonces $S_1$ también es l.i. trivialmente. Supongamos que $k<n$. Entonces, por un Teorema anterior, $0\mathbf{v}_{k+1}+...+0\mathbf{v}_n=\mathbf{0}$ por lo cual lo anterior implica que $$c_1\mathbf{v}_1+c_2\mathbf{v}_2+...+c_k\mathbf{v}_k=\mathbf{0}\iff c_i=0\hspace{3mm}\forall\hspace{1.5mm}  i\in\{1,2, ...,k\}.$$ Por lo tanto, por definición, $S_1$ también es $l.i$.

\end{proof}

Este teorema nos dice que si removemos vectores de un conjunto linealmente independiente, el conjunto resultante también es linealmente independiente. El resultado opuesto se deja como ejercicio.

\end{teo}

\begin{ejer}
    Sean $V$ un espacio vectorial y $S_1,S_2$ subconjuntos de $V$ tales que $S_1\subseteq S_2\subseteq V$. Demuestra que, si $S_1$ es linealmente dependiente, entonces $S_2$ es linealmente dependiente. 
\end{ejer}

\begin{teo}\label{teo: Agregar un elemento que no está en un subespacio generado a un conjunto generador linealmente independiente equivale a que el conjunto siga siendo linealmente independiente}

Sea $V$ un espacio vectorial sobre un campo $K$ y $L\subset V$ un conjunto con $n$ elementos linealmente independientes entre sí. Entonces, para cualquier $\mathbf{v}\in V$, el conjunto $L'\equiv L\cup \{\mathbf{v}\}$ es $l.i. \iff \mathbf{v}\notin \langle L \rangle$.

\begin{proof}
Sea $L=\{\mathbf{u}_1, ... , \mathbf{u}_n\}.$ Supongamos que $\mathbf{v}\in\langle L \rangle$, entonces existen coeficientes $c_i\in K$ tales que $\mathbf{v}=c_1\mathbf{u}_1+...+c_n\mathbf{u}_n.$ Despejando esta ecuación, obtenemos que $c_1\mathbf{u}_1+...+c_n\mathbf{u}_n+(-1)\mathbf{v}=\mathbf{0},$ es decir, que existe una combinación lineal no trivial entre los vectores de $L'$ que dan como resultado al vector nulo, por lo cual $L'$ es un conjunto linealmente dependiente. \\

Por otro lado, supongamos que $L'$ es linealmente dependiente. Entonces, existe una combinación lineal no trivial de los vectores de $L'$ que resulta en el vector nulo, i.e., $c_1\mathbf{u}_2+...+c_n\mathbf{u}_n+b\mathbf{v}=\mathbf{0}$ con al menos un coeficiente distinto de cero. En este caso, el coeficiente $b\neq 0$: si $b$ fuera igual a cero, la ecuación restante sería $c_1\mathbf{u}_1+...+c_n\mathbf{u}_n=\mathbf{0}$; ya que $L$ es linealmente independiente, entonces todos los vectores $c_i$ deben ser iguales a cero pero, ya que estamos suponiendo que también $b=0$, entonces el conjunto $L'$ también sería linealmente independiente, contradiciendo la hipótesis. Así, sabiendo que $b\neq 0$ podemos despejar la ecuación $c_1\mathbf{u}_1+...+c_n\mathbf{u}_n+b\mathbf{v}=\mathbf{0}$ y obtener que $\mathbf{v}=\frac{-c_1}{b}\mathbf{u}_1+...+\frac{-c_n}{b}\mathbf{u}_n$, lo cual implica que $\mathbf{v}\in\langle L \rangle.$

\end{proof}

    La demostración de este teorema nos dice que si tenemos un conjunto linealmente independiente y agregamos a un vector de su subespacio generado a este conjunto, entonces se vuelve linealmente dependiente. En contraposición, concluimos que en cualquier conjunto linealmente dependiente existe una especie de \emph{redundancia} entre sus elementos, ya que se puede remover a cualquiera de ellos sin alterar el subespacio generado por este conjunto. En cambio, remover un vector de un conjunto linealmente independiente \emph{sí} altera el subespacio generado por ese conjunto.
\end{teo}

\newpage
\subsection*{Bases y dimensión} \label{Ssec:Bases y dimensión}

Como hemos visto en secciones anteriores, cualquier vector de un espacio vectorial se puede expresar como combinación lineal de otros vectores de ese mismo espacio\footnote{De lo contrario, se violarían las propiedades de cerradura de los espacios vectoriales.}. Cuando trabajamos en un espacio vectorial $V$, resulta conveniente tener un conjunto de vectores $B\subseteq V$ con el cual se pueda expresar a \emph{cualquier vector del espacio vectorial} $V$ de forma \emph{única} \textemdash lo cual se logra, precisamente, a través de una combinación lineal única de los vectores del conjunto $B$. Tomando en cuenta el Teorema \ref{teo:Unicidad de combinación lineal en independencia lineal}, vemos que los conjuntos linealmente independientes son buenos candidatos para lograr que las expresiones mediante combinaciones lineales sean \emph{únicas}, por lo cual pediremos que $B$ sea linealmente independiente; además, ya que queremos ser capaces de expresar a \emph{cualquier} vector arbitrario de $V$ como combinación lineal \emph{única} de los vectores de $B$, sería necesario que el conjunto linealmente independiente $B$ generara a \emph{todos} los vectores de $V$. A cualquier conjunto que cumpla ambas propiedades se le conoce como una \emph{base} para el espacio vectorial en cuestión.

\subsubsection*{Definición de base} \label{Sssec: Definición de base}

\begin{tcolorbox}

    \underline{Def.} Una base de un espacio vectorial $V$ es un conjunto de vectores linealmente independientes que generan a todo el espacio vectorial $V$. En lenguaje matemático, $$B\subset V \hspace{1.5mm}\text{es una base de}\hspace{1.5mm} V \iff B\hspace{1.5mm}\text{es}\hspace{1.5mm} l.i.  \hspace{1.5mm}\text{y}\hspace{1.5mm} \langle B \rangle=V.$$

\end{tcolorbox}

Nótese por la definición que, ya que muchos conjuntos de vectores distintos pueden ser linealmente independientes y generar a un mismo espacio vectorial, un espacio vectorial puede tener muchas bases distintas. Esto implica que cualquier vector arbitrario de un espacio vectorial puede ser expresado a través de diferentes combinaciones lineales (correspondientes a distintas bases del espacio, y únicas para cada base). Dicho de otra forma, dado un espacio vectorial con más de una base, cualquier vector de ese espacio puede ser \emph{representado en las distintas bases} de ese espacio\footnote{El tema de las \emph{representaciones} es de gran interés en algunas ramas de las matemáticas y sus aplicaciones son de suma importancia en varias áreas de la física. En este curso, lo veremos sobre todo en las secciones de representación matricial de una transformación lineal, representación de una matriz en distintas bases y representaciones de un operador lineal en distintos espacios vectoriales.}.

\subsubsection*{Ejemplos de bases} \label{Ejem:Bases}

El conjunto $\{1\}$ es una base para el espacio vectorial complejo $\mathbb{C}.$ De hecho, si cambiamos a $1$ en el conjunto anterior por cualquier número complejo no nulo, también tendremos una base para el espacio complejo $\mathbb{C}$. ¿A qué propiedades se debe esto?. 
\vspace{3mm}

Los conjuntos $\{\begin{pmatrix} 2 & 0 \end{pmatrix}, \begin{pmatrix} 0, & -3 \end{pmatrix}\}, \{\begin{pmatrix} 3 & 3 \end{pmatrix}, \begin{pmatrix} -3 & 3 \end{pmatrix}\}$ y $\{\begin{pmatrix} 1 & 0 \end{pmatrix},\begin{pmatrix} 0 & 1 \end{pmatrix}\}$ son bases de $\mathbb{R}^2$.
\vspace{3mm}

Cualquier conjunto de la forma $\{c_n x^n\hspace{0.5mm}|\hspace{0.5mm}n\in\mathbb{N}\cup\{0\}, c_n\in \mathbb{R}\}$ es una base del espacio vectorial de las funciones polinomiales de grado $n$.

\subsubsection*{Teorema de reemplazamiento} \label{Subsubsec:Teo_de_reemplazamiento}

A continuación, veremos un importante teorema que nos ayudará a construir bases más adelante.

\begin{teo}
    Sea $V$ un espacio vectorial generado por un conjunto $G$ con $n$ vectores, y sea $L$ un subconjunto linealmente independiente de $V$ con $m$ vectores. Entonces $m\le n$ y existe un subconjunto $H\subseteq G$ que contiene $n-m$ vectores tal que $L\cup H$ genera a $V$.

    \begin{proof}
        Esta demostración se hará por inducción. \\

    \textbf{Base inductiva}
    Sea $m=0$, entonces $L=\emptyset$. Si tomamos $H=G$ obtenemos el resultado deseado. \\

    \textbf{Hipótesis de inducción}
    Supongamos que la hipótesis del teorema se cumple para $L=\{\mathbf{v}_1,...,\mathbf{v}_m\}$ con $m>0$. \\

    \textbf{Paso inductivo}
    Ahora debemos demostrar que, bajo la hipótesis de inducción (donde el teorema se cumple para alguna $m>0$), el teorema se debe cumplir para $m+1$. \\
    
    Sea $L=\{\mathbf{v}_1,...,\mathbf{v}_{m+1}\}$ un subconjunto linealmente independiente de $V$. Por el Teorema \ref{teo: Remover vectores a un conjunto linealmente independiente da un conjunto linealmente independiente} el conjunto $\{\mathbf{v}_1,...,\mathbf{v}_m\}$ es l.i., por lo cual podemos aplicar la hipótesis de inducción y concluir que $m\le n$ y que existe un subconjunto $\{\mathbf{u}_1,...,\mathbf{u}_{n-m}\}\subset G$ tal que $\{\mathbf{v}_1,...,\mathbf{v}_m\}\cup\{\mathbf{u}_1,...,\mathbf{u}_{n-m}\}$ genera a $V$. Por lo tanto, existen escalares $a_1,...,a_m,b_1,...,b_{n-m}$ tales que \[
        a_1\mathbf{v}_1+...+a_m\mathbf{v}_m+b_1\mathbf{u}_1+...+b_{n-m}\mathbf{u}_{n-m}=\mathbf{v}_{m+1}.
    .\] 
    Observemos que, ya que $L$ es linealmente independiente, $n-m>0\implies n>m\implies n\ge m+1$. Además, alguna $b_i$ debe ser distinta de cero, por lo cual podemos despejarla (de lo contrario, estaríamos contradiciendo la hipótesis de inducción, que nos asegura que $\{\mathbf{v}_1,...,\mathbf{v}_m\}$ es l.i.). Suponiendo, por ejemplo, que $b_1\neq 0$, tenemos que \[
        \mathbf{u}_1=\frac{-a_1}{b_1}\mathbf{v}_1+...+\frac{-a_m}{b_1}\mathbf{v}_m+\frac{-b_2}{b_1}\mathbf{u}_2+...+\frac{-b_{n-m}}{b_1}\mathbf{u}_{n-m}
    ,\] 
    por lo cual $\mathbf{u}_1$ puede ser expresado como combinación lineal de los vectores $\mathbf{v}_1,...,\mathbf{v}_m,\mathbf{u}_2,...,\mathbf{u}_{n-m}.$ Sea $H=\{\mathbf{u}_2,...,\mathbf{u}_{n-m}\}$, entonces $L\cup H=\{\mathbf{v}_1,...,\mathbf{v}_{m+1},\mathbf{u}_2,...,\mathbf{u}_{n-m}\}$ y trivialmente tenemos que $\mathbf{v}_1,...,\mathbf{v}_m,\mathbf{u}_2,...,\mathbf{u}_{n-m}\in\langle L\cup H\rangle$ \textemdash lo cual también implica que $\mathbf{u}_1\in\langle L\cup H\rangle$. Por lo tanto, tenemos que $\{\mathbf{v}_1,...,\mathbf{v}_m,\mathbf{u}_1,...,\mathbf{u}_{n-m}\}\subseteq\langle L\cup H\rangle.$ Recordando que por hipótesis de inducción $\{\mathbf{v}_1,...,\mathbf{v}_m,\mathbf{u}_1,...,\mathbf{u}_{n-m}\}$ genera a $V$, entonces el hecho de que esté contenido en $L\cup H$ implica necesariamente que $\langle L\cup H\rangle=V.$ Finalmente, ya que $H$ es un subconjunto de $G$ con $(n-m)-1=n-(m+1)$ vectores, el teorema se cumple para $m+1$, terminando así nuestra demostración.
    \end{proof}
\end{teo}

El teorema anterior se conoce como el teorema de \emph{reemplazamiento} ya que, partiendo de un conjunto linealmente independiente $L$ y otro conjunto $H$ que juntos cumplen $\langle L\cup H \rangle=V$ (sin que $L\cup H$ sea necesariamente l.i.), lo que estamos haciendo con cada paso consecutivo de la inducción es reemplazar a los vectores de $H$ por vectores que podemos añadir a $L$ tal que este conjunto siga siendo linealmente independiente y se siga cumpliendo que la unión de ambos genere a $V$. De esta forma, $L$ es un conjunto linealmente independiente que va creciendo y que cada vez necesita a menos vectores de $H$ para poder, a través de la unión generar a $V$. ¿Qué pasará cuando $L$ sea un conjunto linealmente independiente que no necesita a ningún vector de $H$ para generar a $V$\footnote{Recuerda para qué dijimos que nos serviría este teorema.}?. 

\begin{ejer}
    Considera al espacio vectorial $\mathbb{R}^n$ para distintos valores de $n$ y responde: ¿A partir de qué cardinalidad cualquier conjunto de vectores de $\mathbb{R}^n$ es necesariamente linelmente dependiente?
\end{ejer}

\newpage
\subsection*{Dimensión} \label{Subsec:Dimensión}

Como quizá notaste en los ejemplos de la sección anterior, pareciera que todas las bases de un mismo espacio vectorial tienen el mismo número de elementos. A continuación, demostraremos este hecho.

\begin{teo}\label{teo: Todas las bases de un mismo espacio vectorial tienen el mismo número de elementos}

    Sean $B=\{\mathbf{b}_1,\mathbf{b}_2, ..., \mathbf{b}_n\}$ y $B'=\{\mathbf{b'}_1,\mathbf{b'}_2, ..., \mathbf{b'}_{n'}\}$ bases de $V$, entonces $n=n'$.

\begin{proof}

    Supongamos que $n'>n$. Ya que $B'\subset V$ y $\langle B \rangle =V\implies B'\subset\langle B \rangle,$ por lo cual podemos expresar cualquier vector de $B'$ como combinación lineal de los de $B$. Entonces, 

    $$\mathbf{b'}_1=c_{11}\mathbf{b}_1+c_{12}\mathbf{b}_2+...+c_{1n}\mathbf{b}_{n},$$

    $$...$$

    $$\mathbf{b'}_{n'}=c_{n'1}\mathbf{b}_1+c_{n'2}\mathbf{b}_2+...+c_{n'n}\mathbf{b}_n,$$ \noindent donde $c_{ij}\in K$. \\

    Sea $\mathbf{z}\in V$ un vector arbitrario. Como $B'$ es base de $V\implies \mathbf{z}=d_1\mathbf{b'}_1+d_2\mathbf{b'}_2+...+d_{n'}\mathbf{b}_{n'}$. Sustituyendo con las ecuaciones, obtenemos que $$\mathbf{z}=d_1(c_{11}\mathbf{b}_1+...+c_{1n}\mathbf{b}_n)+...+d_{n'}(c_{n'1}\mathbf{b}_1+...+c_{n'n}\mathbf{b}_n)=(d_1 c_{11}+...+d_{n'} c_{n'1})\mathbf{b}_1+...+(d_1 c_{1n}+...+d_{n'} c_{n'n})\mathbf{b}_n.$$ \noindent En particular, si $\mathbf{z}=\mathbf{0}$, ya que por hipótesis $B$ es linealmente independiente, obtenemos

    $$d_1 c_{11}+...+d_{n'}c_{n'1}=0,$$


    $$...$$ 

    $$d_1 c_{1n}+...+d_{n'} c_{n'n}=0.$$
    Sin embargo, ya que al inicio de la demostración supusimos que $n'>n$, entonces el sistema de ecuaciones anterior tiene más incógnitas que ecuaciones y, por ende, una solución no trivial para $(d_1, d_2, ..., d_{n'})$. Esto contradice el hecho de que $B$ sea una linealmente independiente, por lo cual tampoco podría ser una base. Análogamente, si $n>n'$ se llega a una contradicción similar. Por lo tanto, por tricotomía concluimos que, si $B$ y $B'$ son bases, $n=n'$.
\end{proof}

\end{teo}

El hecho de que todas las bases de un mismo espacio vectorial tengan el mismo número de elementos motiva la siguiente definición.

\begin{tcolorbox}

    \underline{Def.} La \emph{dimensión} de un espacio vectorial $V$ es igual al número de elementos (i.e., la cardinalidad) de cualquiera de sus bases. Si cualquier base de $V$ tiene un número finito $n$ de elementos, decimos que $V$ es un \emph{espacio de dimensión (finita)} $n$ y escribimos esto como $\text{dim}(V)=n$; de lo contrario decimos que $V$ es un espacio de dimensión \emph{infinita}\footnote{En el resto de estas notas, supondremos que los espacios vectoriales mencionados tienen dimensión finita, a menos que se indique lo contrario.}.

\end{tcolorbox}

\begin{ejer}
    Sean $K$ un campo arbitrario y $\mathbf{e}_1=\begin{pmatrix} 1 & 0 & 0 & 0 & ... & 0 \end{pmatrix}, \mathbf{e}_2=\begin{pmatrix} 0 & 1 & 0 & 0 & ... & 0 \end{pmatrix}, ..., \mathbf{e}_n = \begin{pmatrix} 0 & 0 & 0 & 0 & ... & 1 \end{pmatrix}$. Demuestra que $\{\mathbf{e}_1, \mathbf{e}_2, ..., \mathbf{e}_n\}$ es una base para $(K^n,K)$ y que, por lo tanto, $\text{dim}(K^n,K)=n$.
\end{ejer}

Observemos que esta definición \emph{algebráica} de dimensión difiere de las definiciones geométricas y físicas usuales de dimensión. Por ejemplo, a pesar de que el espacio vectorial complejo $\mathbb{C}$ se represente en el plano cartesiano \textemdash el cual tiene dimensión geométrica $2$\textemdash\hspace{0.5mm}, este espacio vectorial es de dimensión (algebráica) $1$, como vimos en los ejemplos de la sección \ref{Ejem:Bases}. Otra observación es que la dimensión de un espacio vectorial no sólo depende del conjunto vectorial, sino también del campo sobre el cual se define, como en el siguiente ejercicio.

\begin{ejer}
    Demuestra que $\text{dim}(\mathbb{C},\mathbb{C})=1$ pero $\text{dim}(\mathbb{C},\mathbb{R})=2$.
\end{ejer}

\begin{teo}\label{teo: Dimensión de subespacios de un espacio de dimensión finita}
    Sea $V$ un espacio vectorial de dimensión finita y $W$ un subespacio de $V$, entonces W tiene dimensión finita y $\text{dim}(W)\le \text{dim}(V).$ 
\begin{proof}

    Sea $\text{dim}(V)=n.$ Si $W=\{\mathbf{0}\} \implies \text{dim}(W)=0\le n.$ Consideremos ahora que $W$ contiene a un vector no nulo $\mathbf{x}_1$, entonces el conjunto $\{\mathbf{x}_1\}$ es linealmente independiente. Supongamos que seguimos agregando más vectores $\mathbf{x}_2,...,\mathbf{x}_k$ de $W$ al conjunto $\{\mathbf{x}_1\} $ de tal forma que $\{\mathbf{x}_1,\mathbf{x}_2,...,\mathbf{x}_k\}$ sea linealmente independiente. Ya que $\text{dim}(V)=n,$ entonces cualquier base de $V$ tiene $n$ elementos. Esto implica que ningún subconjunto de $V$ linealmente independiente puede tener más de $n$ elementos, por lo cual el proceso anterior debe detenerse para algún $k\le n.$ De acuerdo a un Teorema anterior, este conjunto genera a $W$, por lo cual forma una base de $W$, de donde concluimos que $\text{dim}(W)=k\le n.$

\end{proof}

\end{teo}

En los teoremas anteriores demostramos que si $\text{dim}(V)=n$ entonces cualquer base de $V$ tiene precisamente $n$ elementos, y que cualquier subespacio vectorial tiene dimensión finita. Resulta, además, que en este caso cualquier conjunto de $n$ vectores linealmente independientes de $V$ es también una base para $V$\textemdash es decir, que también genera a todo el espacio $V$, como veremos en el siguiente teorema. 

\begin{teo}\label{teo: Conjunto linealmente independiente con cardinalidad igual a la dimensión finita del espacio es una base}

    Sea $V$ un espacio vectorial. Si $\text{dim}(V)=n$ entonces cualquier conjunto de $n$ vectores linealmente independientes de $V$ es una base de $V$.

\begin{proof}

    Esta prueba se hará por contradicción. \\

    Sea $V$ un espacio vectorial con $\text{dim}(V)=n, \hspace{1.5mm} n\in\mathbb{N}$ y $B=\{\mathbf{b}_1, ..., \mathbf{b}_n\}\subset V$ un conjunto de $n$ vectores de $V$ que son linealmente independientes entre sí. \\

    Supongamos que $\langle B \rangle \neq V$, es decir, que $\exists\hspace{1.5mm} \mathbf{b}_{n+1}\in V$ tal que éste no puede ser expresado como combinación lineal de los vectores de $B$. Por definición, entonces dicho vector es linealmente independiente de los vectores de $B$. Por lo tanto, podemos definir al conjunto $B'\equiv\{\mathbf{b}_1, ...,\mathbf{b}_n, \mathbf{b}_{n+1}\}$, que tiene $n+1$ elementos linealmente independientes entre sí. Supongamos que, ahora sí, $\langle B' \rangle = V$; en ese caso, por definición, $B'$ sería una base de $V$. Sin embargo, ya que $\text{dim}(V)=n$, por lo demostrado en el Teorema 4.2.1 hemos llegado a una contradicción, ya que cualquier base de $V$ debe tener exactamente $n$ elementos. \\
    
    Ya que la suposición $\langle B \rangle \neq V$ fue la que nos llevó a esta contradicción, tenemos que $\langle B \rangle = V$, por lo cual $B$ \textemdash un conjunto arbitrario de $n$ elementos linealmente independientes de $V$\textemdash \hspace{1mm} \emph{es} una base de $V$.

\end{proof}

\end{teo}

\begin{coro}\label{coro: Subespacio igual a espacio de dimensión finita si sus dimensiones son iguales}
    Sean $V$ es un espacio vectorial de dimensión finita y $W$ un subespacio vectorial de $V$. Entonces, $\text{dim}(W)=\text{dim}(V)$ implica que $W=V$.
\end{coro}

\begin{proof}
    Se sigue del Teorema \ref{teo: Conjunto linealmente independiente con cardinalidad igual a la dimensión finita del espacio es una base}.
\end{proof}

\begin{ejer}
    Sea $V$ un espacio vectorial de dimensión $n$ y $D$ un conjunto linealmente dependiente tal que $\langle D \rangle =V$. Demuestra que $D$ tiene más de $n$ elementos. 
\end{ejer}

Para terminar esta sección, veremos algunas formas en las cuales se pueden construir bases de un espacio vectorial de dimensión $n$ a partir de conjuntos linealmente independientes con menos de $n$ elementos, o de conjuntos linealmente dependientes que generan $V$ y tienen más de $n$ elementos.

\begin{teo}\label{teo: Conversión de conjunto generador en base para espacios de dimensión finita}
    Sea $V$ un espacio vectorial de dimensión $n$, entonces cualquier conjunto finito linealmente dependiente que genera a $V$ puede reducirse hasta convertirse en una base de $V$.
\end{teo}

\begin{proof}
    Sea $D$ un conjunto finito linealmente dependiente tal que $\langle D \rangle =V$. Ya que $D$ es linealmente dependiente, entonces existe un vector $\mathbf{v}$ que puede ser expresado como combinación lineal de los demás por lo cual, definiendo $D'=D\setminus\{\mathbf{v}\}$ tenemos que $\mathbf{v}\in\langle D' \rangle$, donde claramente $D'$ también es finito. Por el Teorema \ref{teo: Agregar un elemento de un subespcio generado al conjunto generador deja al subespacio generado invariante} sabemos que $\langle D' \rangle =\langle D \rangle =V$. Si el conjunto generador $D'$ no es linealmente independiente, podemos seguir retirando vectores de la misma forma sin afectar su espacio generado hasta obtener un conjunto linealmente independiente que genera a $V$, es decir, una base para $V$.
\end{proof}

\begin{teo}\label{teo: Conversión de conjunto linealmente independiente en base para espacios de dimensión finita}
Sea $V$ un espacio vectorial de dimensión $n$, entonces cualquier conjunto linealmente independiente con menos de $n$ elementos no genera a $V$, pero puede extenderse hasta convertirse en una base de $V$.

\begin{proof}
    Sea $L$ un conjunto linealmente independiente con $m$ elementos, donde $m<n$. Entonces $L$ no genera a $V$ ya que, de lo contrario, sería una base de $V$ y tendríamos dos bases de $V$ con diferente cardinalidad, lo cual contradice al Teorema \ref{teo: Todas las bases de un mismo espacio vectorial tienen el mismo número de elementos}. Sea $S$ un conjunto generador de $V$. Ya que $L$ no genera a $V$, debe haber algún vector en $\mathbf{v}\in S$ tal que $\mathbf{v}\notin \langle L \rangle$. Definimos ahora al conjunto $L'=L\cup \{\mathbf{v}\}$ el cual, por el Teorema \ref{teo: Agregar un elemento que no está en un subespacio generado a un conjunto generador linealmente independiente equivale a que el conjunto siga siendo linealmente independiente} , es linealmente independiente. Si $L'$ no genera a $V$, podemos repetir el proceso hasta llegar a un conjunto linealmente independiente que genera a $V$, i.e., una base para $V$.
\end{proof}

\end{teo}

Sabiendo que un mismo espacio vectorial puede tener muchas bases diferentes \textemdash todas con el mismo número de elementos\textemdash \hspace{1mm}, en la siguiente sección nos enfocaremos a ver algunos tipos de bases que resultan ser útiles comunmente, y a entender cómo podemos construirlas y usarlas. 

\end{document}
